{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18323,"status":"ok","timestamp":1663842871785,"user":{"displayName":"김화정","userId":"08769136370942470221"},"user_tz":-540},"id":"n5PFVEB9AH3i","outputId":"215ee2d1-e09f-41f7-9746-b0ce2e9b3d8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"lNhvzwRIwFBP","executionInfo":{"status":"ok","timestamp":1663852034403,"user_tz":-540,"elapsed":901,"user":{"displayName":"김화정","userId":"08769136370942470221"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n"," \n","\n","def iou(y_true, y_pred):\n","\n","    def f(y_true, y_pred):\n","\n","        intersection = (y_true * y_pred).sum()\n","\n","        union = y_true.sum() + y_pred.sum() - intersection\n","\n","        x = (intersection + 1e-15) / (union + 1e-15)\n","\n","        x = x.astype(np.float32)\n","\n","        return x\n","\n","    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n","\n","\n","smooth = 1e-15\n","\n","\n","def dice_coef(y_true, y_pred):\n","\n","    y_true = tf.keras.layers.Flatten()(y_true)\n","\n","    y_pred = tf.keras.layers.Flatten()(y_pred)\n","\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","\n","    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n","\n"," \n","def dice_loss(y_true, y_pred):\n","\n","    return 1.0 - dice_coef(y_true, y_pred)"]},{"cell_type":"code","source":["#model\n","\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout\n","from keras.layers import Input, Activation, Conv2D, MaxPooling2D, UpSampling2D, Dropout,BatchNormalization, AveragePooling2D\n","from tensorflow.keras.models import Model\n","\n"," \n","def mnet(input_shape):\n","\n","    # Input\n","    input1 = Input(input_shape)\n","\n","\n","    # Encoder\n","    conv1 = Conv2D(64, (1, 1), padding='same')(input1 )\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Activation('relu')(conv1)\n","    conv1 = Dropout(0.2)(conv1)\n","\n","    conv1 = Concatenate()([input1 , conv1])\n","    conv1 = Conv2D(64, (1, 1), padding='same')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Activation('relu')(conv1)\n","    pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n","\n","\n","\n","\n","    #\n","    input2 = MaxPool2D(pool_size=(2, 2))(input1)\n","    conv21 = Concatenate()([input2 , pool1])\n","    conv2 = Conv2D(128, (1, 1), padding='same')(conv21)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Activation('relu')(conv2)\n","    conv2 = Dropout(0.2)(conv2)\n","\n","    conv2 = Concatenate()([conv21, conv2])\n","    conv2 = Conv2D(128, (1, 1), padding='same')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Activation('relu')(conv2)\n","    pool2 = MaxPool2D(pool_size=(2, 2))(conv2)\n","\n","\n","    #\n","\n","    input3 = MaxPool2D(pool_size=(2, 2))(input2)\n","\n","\n","    conv31 = Concatenate()([input3 , pool2])\n","    conv3 = Conv2D(256, (1, 1), padding='same')(conv31 )\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Activation('relu')(conv3)\n","    conv3 = Dropout(0.2)(conv3)\n","\n","    conv3 = Concatenate()([conv31, conv3])\n","    conv3 = Conv2D(256, (1, 1), padding='same')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Activation('relu')(conv3)\n","    pool3 = MaxPool2D(pool_size=(2, 2))(conv3)\n","\n","\n","\n","\n","\n","    #\n","    input4 = MaxPool2D(pool_size=(2, 2))(input3)\n","\n","\n","    conv41 = Concatenate()([input4 , pool3])\n","    conv4 = Conv2D(512, (1, 1), padding='same')(conv41 )\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Activation('relu')(conv4)\n","    conv4 = Dropout(0.2)(conv4)\n","\n","    conv4 = Concatenate()([conv41, conv4])\n","    conv4 = Conv2D(512, (1, 1), padding='same')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Activation('relu')(conv4)\n","    pool4 = MaxPool2D(pool_size=(2, 2))(conv4)\n","\n","\n","    #\n","    input5 = MaxPool2D(pool_size=(2, 2))(input4)\n","\n","\n","    conv51 = Concatenate()([input5 , pool4])\n","    conv5 = Conv2D(1024, (1, 1), padding='same')(conv51)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Activation('relu')(conv5)\n","    conv5 = Dropout(0.2)(conv5)\n","\n","    conv5 = Concatenate()([conv51, conv5])\n","    conv5 = Conv2D(1024, (1, 1), padding='same')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Activation('relu')(conv5)\n","\n"," \n","    # Decoder\n","    conv6 = UpSampling2D(size=(2, 2))(conv5)\n","\n","    conv61 = Concatenate()([conv4, conv6])\n","    #conv61 = cbam_block(conv61)\n","    conv6 = Conv2D(512, (3, 3), padding='same')(conv61)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Activation('relu')(conv6)\n","    conv6 = Dropout(0.2)(conv6)\n","\n","    conv6 = Concatenate()([conv61, conv6])\n","    conv6 = Conv2D(512, (3, 3), padding='same')(conv6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Activation('relu')(conv6)\n","    conv62 = Concatenate()([conv6, conv61])\n","\n","    \n","    #\n","    conv7 = UpSampling2D(size=(2, 2))(conv6)\n","    conv71 = Concatenate()([conv3, conv7])\n","    #conv71 = cbam_block(conv71)\n","    conv7 = Conv2D(256, (3, 3), padding='same')(conv71)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Activation('relu')(conv7)\n","    conv7 = Dropout(0.2)(conv7)\n","\n","    conv7 = Concatenate()([conv71, conv7])\n","    conv7 = Conv2D(256, (3, 3), padding='same')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Activation('relu')(conv7)\n","    conv72 = Concatenate()([conv71, conv7])\n","\n","    #\n","    conv8 = UpSampling2D(size=(2, 2))(conv7)\n","    conv81 = Concatenate()([conv2, conv8])\n","    #conv81 = cbam_block(conv81)\n","    conv8 = Conv2D(128, (3, 3), padding='same')(conv81)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = Activation('relu')(conv8)\n","    conv8 = Dropout(0.2)(conv8)\n","\n","    conv8 = Concatenate()([conv81, conv8])\n","    conv8 = Conv2D(128, (3, 3), padding='same')(conv8)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = Activation('relu')(conv8)\n","    conv82 = Concatenate()([conv81, conv8])\n","    \n","\n","    \"\"\"\n","    # Final\n","    conv101 = UpSampling2D(size=(8, 8))(conv6)\n","    conv102 = UpSampling2D(size=(4, 4))(conv7)\n","    conv103 = UpSampling2D(size=(2, 2))(conv8)\n","    #outputs = Conv2D(1, 1, activation='sigmoid')(conv10)\n","    \"\"\"\n","\n","    #\n","    conv9 = UpSampling2D(size=(2, 2))(conv8)\n","    conv91 = Concatenate()([conv1, conv9])\n","    #conv91 = cbam_block(conv91)\n","    conv9 = Conv2D(64, (3, 3), padding='same')(conv91)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Activation('relu')(conv9)\n","    conv9 = Dropout(0.2)(conv9)\n","    \n","    conv9 = Concatenate()([conv91, conv9])\n","    conv9 = Conv2D(64, (3, 3), padding='same')(conv9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Activation('relu')(conv9)\n","\n","\n","\n","    #첫번째 다리\n","    conv111 = Concatenate()([conv6, conv62])\n","    conv112 = Concatenate()([conv7, conv72])\n","    conv113 = Concatenate()([conv8, conv82])\n","\n","    \n","    #두번째 다리 추가\n","    conv211 = Concatenate()([conv61, conv111])\n","    conv212 = Concatenate()([conv71, conv112])\n","    conv213 = Concatenate()([conv81, conv113])\n","\n","    conv211 = UpSampling2D(size=(8, 8))(conv211)\n","    conv212 = UpSampling2D(size=(4, 4))(conv212)\n","    conv213 = UpSampling2D(size=(2, 2))(conv213)\n","    conv12 = Concatenate()([conv211, conv212, conv213, conv9])\n","\n","\n","    outputs = Conv2D(1, 1, activation='sigmoid')(conv12)\n","\n","\n","    model = Model(input1, outputs)\n","    return model"],"metadata":{"id":"PF5HweurkynM","executionInfo":{"status":"ok","timestamp":1663852036760,"user_tz":-540,"elapsed":1192,"user":{"displayName":"김화정","userId":"08769136370942470221"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["#channel_attention\n","\n","from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.activations import sigmoid\n","import tensorflow as tf\n","\n","def channel_att(input_feature, ratio=8):\n","\t\n","\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","\tchannel = input_feature.shape[channel_axis]\n","\n","\tshared_layer_one = Dense(channel//ratio,\n","\t\t\t\t\t\t\t activation='relu',\n","\t\t\t\t\t\t\t kernel_initializer='he_normal',\n","\t\t\t\t\t\t\t use_bias=True,\n","\t\t\t\t\t\t\t bias_initializer='zeros')\n","\tshared_layer_two = Dense(channel,\n","\t\t\t\t\t\t\t kernel_initializer='he_normal',\n","\t\t\t\t\t\t\t use_bias=True,\n","\t\t\t\t\t\t\t bias_initializer='zeros')\n","\t\n","\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n","\tavg_pool = Reshape((1,1,channel))(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel)\n","\tavg_pool = shared_layer_one(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n","\tavg_pool = shared_layer_two(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel)\n","\t\n","\tmax_pool = GlobalMaxPooling2D()(input_feature)\n","\tmax_pool = Reshape((1,1,channel))(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel)\n","\tmax_pool = shared_layer_one(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n","\tmax_pool = shared_layer_two(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel)\n","\t\n","\tchannel_feature = Add()([avg_pool,max_pool])\n","\tchannel_feature = Activation('sigmoid')(channel_feature)\n","\t\n","\tif K.image_data_format() == \"channels_first\":\n","\t\tchannel_feature = Permute((3, 1, 2))(channel_feature)\n","  \n","\tchannel_feature = multiply([input_feature, channel_feature])\n","\treturn channel_feature"],"metadata":{"id":"j-YbkTG-3z7-","executionInfo":{"status":"ok","timestamp":1663847246932,"user_tz":-540,"elapsed":4,"user":{"displayName":"김화정","userId":"08769136370942470221"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["#attention\n","\n","from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.activations import sigmoid\n","import tensorflow as tf\n","\n","def attach_attention_module(net, attention_module):\n","  if attention_module == 'se_block': # SE_block\n","    net = se_block(net)\n","  elif attention_module == 'cbam_block': # CBAM_block\n","    net = cbam_block(net)\n","  else:\n","    raise Exception(\"'{}' is not supported attention module!\".format(attention_module))\n","\n","  return net\n","\n","def se_block(input_feature, ratio=8):\n","\t\"\"\"Contains the implementation of Squeeze-and-Excitation(SE) block.\n","\tAs described in https://arxiv.org/abs/1709.01507.\n","\t\"\"\"\n","\t\n","\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","\tchannel = input_feature.shape[channel_axis]\n","\n","\tse_feature = GlobalAveragePooling2D()(input_feature)\n","\tse_feature = Reshape((1, 1, channel))(se_feature)\n","\tassert se_feature.shape[1:] == (1,1,channel)\n","\tse_feature = Dense(channel // ratio,\n","\t\t\t\t\t   activation='relu',\n","\t\t\t\t\t   kernel_initializer='he_normal',\n","\t\t\t\t\t   use_bias=True,\n","\t\t\t\t\t   bias_initializer='zeros')(se_feature)\n","\tassert se_feature.shape[1:] == (1,1,channel//ratio)\n","\tse_feature = Dense(channel,\n","\t\t\t\t\t   activation='sigmoid',\n","\t\t\t\t\t   kernel_initializer='he_normal',\n","\t\t\t\t\t   use_bias=True,\n","\t\t\t\t\t   bias_initializer='zeros')(se_feature)\n","\tassert se_feature.shape[1:] == (1,1,channel)\n","\tif K.image_data_format() == 'channels_first':\n","\t\tse_feature = Permute((3, 1, 2))(se_feature)\n","\n","\tse_feature = multiply([input_feature, se_feature])\n","\treturn se_feature\n","\n","def cbam_block(cbam_feature, ratio=8):\n","\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n","\tAs described in https://arxiv.org/abs/1807.06521.\n","\t\"\"\"\n","\t\n","\tcbam_feature = channel_attention(cbam_feature, ratio)\n","\tcbam_feature = spatial_attention(cbam_feature)\n","\treturn cbam_feature\n","\n","def channel_attention(input_feature, ratio=8):\n","\t\n","\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","\tchannel = input_feature.shape[channel_axis]\n","\t\n","\tshared_layer_one = Dense(channel//ratio,\n","\t\t\t\t\t\t\t activation='relu',\n","\t\t\t\t\t\t\t kernel_initializer='he_normal',\n","\t\t\t\t\t\t\t use_bias=True,\n","\t\t\t\t\t\t\t bias_initializer='zeros')\n","\tshared_layer_two = Dense(channel,\n","\t\t\t\t\t\t\t kernel_initializer='he_normal',\n","\t\t\t\t\t\t\t use_bias=True,\n","\t\t\t\t\t\t\t bias_initializer='zeros')\n","\t\n","\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n","\tavg_pool = Reshape((1,1,channel))(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel)\n","\tavg_pool = shared_layer_one(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n","\tavg_pool = shared_layer_two(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel)\n","\t\n","\tmax_pool = GlobalMaxPooling2D()(input_feature)\n","\tmax_pool = Reshape((1,1,channel))(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel)\n","\tmax_pool = shared_layer_one(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n","\tmax_pool = shared_layer_two(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel)\n","\t\n","\tcbam_feature = Add()([avg_pool,max_pool])\n","\tcbam_feature = Activation('sigmoid')(cbam_feature)\n","\t\n","\tif K.image_data_format() == \"channels_first\":\n","\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n","\t\n","\treturn multiply([input_feature, cbam_feature])\n","\n","def spatial_attention(input_feature):\n","\tkernel_size = 7\n","\t\n","\tif K.image_data_format() == \"channels_first\":\n","\t\tchannel = input_feature.shape[1]\n","\t\tcbam_feature = Permute((2,3,1))(input_feature)\n","\telse:\n","\t\tchannel = input_feature.shape[-1]\n","\t\tcbam_feature = input_feature\n","\t\n","\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n","\tassert avg_pool.shape[-1] == 1\n","\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n","\tassert max_pool.shape[-1] == 1\n","\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n","\tassert concat.shape[-1] == 2\n","\tcbam_feature = Conv2D(filters = 1,\n","\t\t\t\t\tkernel_size=kernel_size,\n","\t\t\t\t\tstrides=1,\n","\t\t\t\t\tpadding='same',\n","\t\t\t\t\tactivation='sigmoid',\n","\t\t\t\t\tkernel_initializer='he_normal',\n","\t\t\t\t\tuse_bias=False)(concat)\t\n","\tassert cbam_feature.shape[-1] == 1\n","\t\n","\tif K.image_data_format() == \"channels_first\":\n","\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n","\t\t\n","\treturn multiply([input_feature, cbam_feature])"],"metadata":{"id":"06rXbjZcY2YY","executionInfo":{"status":"ok","timestamp":1663851759786,"user_tz":-540,"elapsed":490,"user":{"displayName":"김화정","userId":"08769136370942470221"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdhDFJyI0_nS","outputId":"0d2b365d-0866-452f-8595-da08613ca032","executionInfo":{"status":"ok","timestamp":1663852115583,"user_tz":-540,"elapsed":71776,"user":{"displayName":"김화정","userId":"08769136370942470221"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/dataset\n","Train: 900 - 900\n","Valid: 300 - 300\n","Test: 300 - 300\n","Model: \"model_4\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_17 (InputLayer)          [(None, 256, 256, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_238 (Conv2D)            (None, 256, 256, 64  256         ['input_17[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_212 (Batch  (None, 256, 256, 64  256        ['conv2d_238[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_236 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_212[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," dropout_106 (Dropout)          (None, 256, 256, 64  0           ['activation_236[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_273 (Concatenate)  (None, 256, 256, 67  0           ['input_17[0][0]',               \n","                                )                                 'dropout_106[0][0]']            \n","                                                                                                  \n"," conv2d_239 (Conv2D)            (None, 256, 256, 64  4352        ['concatenate_273[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_213 (Batch  (None, 256, 256, 64  256        ['conv2d_239[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_237 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_213[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_129 (MaxPooling2  (None, 128, 128, 3)  0          ['input_17[0][0]']               \n"," D)                                                                                               \n","                                                                                                  \n"," max_pooling2d_128 (MaxPooling2  (None, 128, 128, 64  0          ['activation_237[0][0]']         \n"," D)                             )                                                                 \n","                                                                                                  \n"," concatenate_274 (Concatenate)  (None, 128, 128, 67  0           ['max_pooling2d_129[0][0]',      \n","                                )                                 'max_pooling2d_128[0][0]']      \n","                                                                                                  \n"," conv2d_240 (Conv2D)            (None, 128, 128, 12  8704        ['concatenate_274[0][0]']        \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_214 (Batch  (None, 128, 128, 12  512        ['conv2d_240[0][0]']             \n"," Normalization)                 8)                                                                \n","                                                                                                  \n"," activation_238 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_214[0][0]']\n","                                8)                                                                \n","                                                                                                  \n"," dropout_107 (Dropout)          (None, 128, 128, 12  0           ['activation_238[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," concatenate_275 (Concatenate)  (None, 128, 128, 19  0           ['concatenate_274[0][0]',        \n","                                5)                                'dropout_107[0][0]']            \n","                                                                                                  \n"," conv2d_241 (Conv2D)            (None, 128, 128, 12  25088       ['concatenate_275[0][0]']        \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_215 (Batch  (None, 128, 128, 12  512        ['conv2d_241[0][0]']             \n"," Normalization)                 8)                                                                \n","                                                                                                  \n"," activation_239 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_215[0][0]']\n","                                8)                                                                \n","                                                                                                  \n"," max_pooling2d_131 (MaxPooling2  (None, 64, 64, 3)   0           ['max_pooling2d_129[0][0]']      \n"," D)                                                                                               \n","                                                                                                  \n"," max_pooling2d_130 (MaxPooling2  (None, 64, 64, 128)  0          ['activation_239[0][0]']         \n"," D)                                                                                               \n","                                                                                                  \n"," concatenate_276 (Concatenate)  (None, 64, 64, 131)  0           ['max_pooling2d_131[0][0]',      \n","                                                                  'max_pooling2d_130[0][0]']      \n","                                                                                                  \n"," conv2d_242 (Conv2D)            (None, 64, 64, 256)  33792       ['concatenate_276[0][0]']        \n","                                                                                                  \n"," batch_normalization_216 (Batch  (None, 64, 64, 256)  1024       ['conv2d_242[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_240 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_216[0][0]']\n","                                                                                                  \n"," dropout_108 (Dropout)          (None, 64, 64, 256)  0           ['activation_240[0][0]']         \n","                                                                                                  \n"," concatenate_277 (Concatenate)  (None, 64, 64, 387)  0           ['concatenate_276[0][0]',        \n","                                                                  'dropout_108[0][0]']            \n","                                                                                                  \n"," conv2d_243 (Conv2D)            (None, 64, 64, 256)  99328       ['concatenate_277[0][0]']        \n","                                                                                                  \n"," batch_normalization_217 (Batch  (None, 64, 64, 256)  1024       ['conv2d_243[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_241 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_217[0][0]']\n","                                                                                                  \n"," max_pooling2d_133 (MaxPooling2  (None, 32, 32, 3)   0           ['max_pooling2d_131[0][0]']      \n"," D)                                                                                               \n","                                                                                                  \n"," max_pooling2d_132 (MaxPooling2  (None, 32, 32, 256)  0          ['activation_241[0][0]']         \n"," D)                                                                                               \n","                                                                                                  \n"," concatenate_278 (Concatenate)  (None, 32, 32, 259)  0           ['max_pooling2d_133[0][0]',      \n","                                                                  'max_pooling2d_132[0][0]']      \n","                                                                                                  \n"," conv2d_244 (Conv2D)            (None, 32, 32, 512)  133120      ['concatenate_278[0][0]']        \n","                                                                                                  \n"," batch_normalization_218 (Batch  (None, 32, 32, 512)  2048       ['conv2d_244[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_242 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_218[0][0]']\n","                                                                                                  \n"," dropout_109 (Dropout)          (None, 32, 32, 512)  0           ['activation_242[0][0]']         \n","                                                                                                  \n"," concatenate_279 (Concatenate)  (None, 32, 32, 771)  0           ['concatenate_278[0][0]',        \n","                                                                  'dropout_109[0][0]']            \n","                                                                                                  \n"," conv2d_245 (Conv2D)            (None, 32, 32, 512)  395264      ['concatenate_279[0][0]']        \n","                                                                                                  \n"," batch_normalization_219 (Batch  (None, 32, 32, 512)  2048       ['conv2d_245[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_243 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_219[0][0]']\n","                                                                                                  \n"," max_pooling2d_135 (MaxPooling2  (None, 16, 16, 3)   0           ['max_pooling2d_133[0][0]']      \n"," D)                                                                                               \n","                                                                                                  \n"," max_pooling2d_134 (MaxPooling2  (None, 16, 16, 512)  0          ['activation_243[0][0]']         \n"," D)                                                                                               \n","                                                                                                  \n"," concatenate_280 (Concatenate)  (None, 16, 16, 515)  0           ['max_pooling2d_135[0][0]',      \n","                                                                  'max_pooling2d_134[0][0]']      \n","                                                                                                  \n"," conv2d_246 (Conv2D)            (None, 16, 16, 1024  528384      ['concatenate_280[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_220 (Batch  (None, 16, 16, 1024  4096       ['conv2d_246[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_244 (Activation)    (None, 16, 16, 1024  0           ['batch_normalization_220[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," dropout_110 (Dropout)          (None, 16, 16, 1024  0           ['activation_244[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_281 (Concatenate)  (None, 16, 16, 1539  0           ['concatenate_280[0][0]',        \n","                                )                                 'dropout_110[0][0]']            \n","                                                                                                  \n"," conv2d_247 (Conv2D)            (None, 16, 16, 1024  1576960     ['concatenate_281[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_221 (Batch  (None, 16, 16, 1024  4096       ['conv2d_247[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_245 (Activation)    (None, 16, 16, 1024  0           ['batch_normalization_221[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," up_sampling2d_48 (UpSampling2D  (None, 32, 32, 1024  0          ['activation_245[0][0]']         \n"," )                              )                                                                 \n","                                                                                                  \n"," concatenate_282 (Concatenate)  (None, 32, 32, 1536  0           ['activation_243[0][0]',         \n","                                )                                 'up_sampling2d_48[0][0]']       \n","                                                                                                  \n"," conv2d_248 (Conv2D)            (None, 32, 32, 512)  7078400     ['concatenate_282[0][0]']        \n","                                                                                                  \n"," batch_normalization_222 (Batch  (None, 32, 32, 512)  2048       ['conv2d_248[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_246 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_222[0][0]']\n","                                                                                                  \n"," dropout_111 (Dropout)          (None, 32, 32, 512)  0           ['activation_246[0][0]']         \n","                                                                                                  \n"," concatenate_283 (Concatenate)  (None, 32, 32, 2048  0           ['concatenate_282[0][0]',        \n","                                )                                 'dropout_111[0][0]']            \n","                                                                                                  \n"," conv2d_249 (Conv2D)            (None, 32, 32, 512)  9437696     ['concatenate_283[0][0]']        \n","                                                                                                  \n"," batch_normalization_223 (Batch  (None, 32, 32, 512)  2048       ['conv2d_249[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_247 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_223[0][0]']\n","                                                                                                  \n"," up_sampling2d_49 (UpSampling2D  (None, 64, 64, 512)  0          ['activation_247[0][0]']         \n"," )                                                                                                \n","                                                                                                  \n"," concatenate_285 (Concatenate)  (None, 64, 64, 768)  0           ['activation_241[0][0]',         \n","                                                                  'up_sampling2d_49[0][0]']       \n","                                                                                                  \n"," conv2d_250 (Conv2D)            (None, 64, 64, 256)  1769728     ['concatenate_285[0][0]']        \n","                                                                                                  \n"," batch_normalization_224 (Batch  (None, 64, 64, 256)  1024       ['conv2d_250[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_248 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_224[0][0]']\n","                                                                                                  \n"," dropout_112 (Dropout)          (None, 64, 64, 256)  0           ['activation_248[0][0]']         \n","                                                                                                  \n"," concatenate_286 (Concatenate)  (None, 64, 64, 1024  0           ['concatenate_285[0][0]',        \n","                                )                                 'dropout_112[0][0]']            \n","                                                                                                  \n"," conv2d_251 (Conv2D)            (None, 64, 64, 256)  2359552     ['concatenate_286[0][0]']        \n","                                                                                                  \n"," batch_normalization_225 (Batch  (None, 64, 64, 256)  1024       ['conv2d_251[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_249 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_225[0][0]']\n","                                                                                                  \n"," up_sampling2d_50 (UpSampling2D  (None, 128, 128, 25  0          ['activation_249[0][0]']         \n"," )                              6)                                                                \n","                                                                                                  \n"," concatenate_288 (Concatenate)  (None, 128, 128, 38  0           ['activation_239[0][0]',         \n","                                4)                                'up_sampling2d_50[0][0]']       \n","                                                                                                  \n"," conv2d_252 (Conv2D)            (None, 128, 128, 12  442496      ['concatenate_288[0][0]']        \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_226 (Batch  (None, 128, 128, 12  512        ['conv2d_252[0][0]']             \n"," Normalization)                 8)                                                                \n","                                                                                                  \n"," activation_250 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_226[0][0]']\n","                                8)                                                                \n","                                                                                                  \n"," dropout_113 (Dropout)          (None, 128, 128, 12  0           ['activation_250[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," concatenate_289 (Concatenate)  (None, 128, 128, 51  0           ['concatenate_288[0][0]',        \n","                                2)                                'dropout_113[0][0]']            \n","                                                                                                  \n"," conv2d_253 (Conv2D)            (None, 128, 128, 12  589952      ['concatenate_289[0][0]']        \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_227 (Batch  (None, 128, 128, 12  512        ['conv2d_253[0][0]']             \n"," Normalization)                 8)                                                                \n","                                                                                                  \n"," activation_251 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_227[0][0]']\n","                                8)                                                                \n","                                                                                                  \n"," up_sampling2d_51 (UpSampling2D  (None, 256, 256, 12  0          ['activation_251[0][0]']         \n"," )                              8)                                                                \n","                                                                                                  \n"," concatenate_291 (Concatenate)  (None, 256, 256, 19  0           ['activation_237[0][0]',         \n","                                2)                                'up_sampling2d_51[0][0]']       \n","                                                                                                  \n"," conv2d_254 (Conv2D)            (None, 256, 256, 64  110656      ['concatenate_291[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_228 (Batch  (None, 256, 256, 64  256        ['conv2d_254[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_252 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_228[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," dropout_114 (Dropout)          (None, 256, 256, 64  0           ['activation_252[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_284 (Concatenate)  (None, 32, 32, 2048  0           ['activation_247[0][0]',         \n","                                )                                 'concatenate_282[0][0]']        \n","                                                                                                  \n"," concatenate_287 (Concatenate)  (None, 64, 64, 1024  0           ['concatenate_285[0][0]',        \n","                                )                                 'activation_249[0][0]']         \n","                                                                                                  \n"," concatenate_290 (Concatenate)  (None, 128, 128, 51  0           ['concatenate_288[0][0]',        \n","                                2)                                'activation_251[0][0]']         \n","                                                                                                  \n"," concatenate_292 (Concatenate)  (None, 256, 256, 25  0           ['concatenate_291[0][0]',        \n","                                6)                                'dropout_114[0][0]']            \n","                                                                                                  \n"," concatenate_293 (Concatenate)  (None, 32, 32, 2560  0           ['activation_247[0][0]',         \n","                                )                                 'concatenate_284[0][0]']        \n","                                                                                                  \n"," concatenate_294 (Concatenate)  (None, 64, 64, 1280  0           ['activation_249[0][0]',         \n","                                )                                 'concatenate_287[0][0]']        \n","                                                                                                  \n"," concatenate_295 (Concatenate)  (None, 128, 128, 64  0           ['activation_251[0][0]',         \n","                                0)                                'concatenate_290[0][0]']        \n","                                                                                                  \n"," conv2d_255 (Conv2D)            (None, 256, 256, 64  147520      ['concatenate_292[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," concatenate_296 (Concatenate)  (None, 32, 32, 4096  0           ['concatenate_282[0][0]',        \n","                                )                                 'concatenate_293[0][0]']        \n","                                                                                                  \n"," concatenate_297 (Concatenate)  (None, 64, 64, 2048  0           ['concatenate_285[0][0]',        \n","                                )                                 'concatenate_294[0][0]']        \n","                                                                                                  \n"," concatenate_298 (Concatenate)  (None, 128, 128, 10  0           ['concatenate_288[0][0]',        \n","                                24)                               'concatenate_295[0][0]']        \n","                                                                                                  \n"," batch_normalization_229 (Batch  (None, 256, 256, 64  256        ['conv2d_255[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," up_sampling2d_52 (UpSampling2D  (None, 256, 256, 40  0          ['concatenate_296[0][0]']        \n"," )                              96)                                                               \n","                                                                                                  \n"," up_sampling2d_53 (UpSampling2D  (None, 256, 256, 20  0          ['concatenate_297[0][0]']        \n"," )                              48)                                                               \n","                                                                                                  \n"," up_sampling2d_54 (UpSampling2D  (None, 256, 256, 10  0          ['concatenate_298[0][0]']        \n"," )                              24)                                                               \n","                                                                                                  \n"," activation_253 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_229[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," concatenate_299 (Concatenate)  (None, 256, 256, 72  0           ['up_sampling2d_52[0][0]',       \n","                                32)                               'up_sampling2d_53[0][0]',       \n","                                                                  'up_sampling2d_54[0][0]',       \n","                                                                  'activation_253[0][0]']         \n","                                                                                                  \n"," conv2d_256 (Conv2D)            (None, 256, 256, 1)  7233        ['concatenate_299[0][0]']        \n","                                                                                                  \n","==================================================================================================\n","Total params: 24,772,033\n","Trainable params: 24,760,257\n","Non-trainable params: 11,776\n","__________________________________________________________________________________________________\n","900/900 [==============================] - ETA: 0s - loss: 0.1769 - dice_coef: 0.7301 - iou: 0.5876 - recall_4: 0.7785 - precision_4: 0.8501\n","Epoch 1: val_loss improved from inf to 0.31468, saving model to files1/model.h5\n","900/900 [==============================] - 70s 75ms/step - loss: 0.1769 - dice_coef: 0.7301 - iou: 0.5876 - recall_4: 0.7785 - precision_4: 0.8501 - val_loss: 0.3147 - val_dice_coef: 0.6558 - val_iou: 0.4932 - val_recall_4: 0.5494 - val_precision_4: 0.9230 - lr: 1.0000e-04\n"]}],"source":["#train\n","\n","import os\n","#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n","import numpy as np\n","import cv2\n","from glob import glob\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import Recall, Precision\n","#from model import build_unet\n","#from metrics import dice_coef, iou\n","\n","H = 256\n","W = 256\n","\n","def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def shuffling(x, y):\n","    x, y = shuffle(x, y, random_state=42)\n","    return x, y\n","\n","def load_data(dataset_path, split=0.2):\n","    #dataset_path = os.getcwd()\n","    dataset_path=dataset_path+\"/drive/MyDrive/Colab Notebooks/dataset\"\n","    print(dataset_path)\n","    images = sorted(glob(os.path.join(dataset_path, \"images\", \"*.jpg\")))\n","    masks = sorted(glob(os.path.join(dataset_path, \"tooth-semantic-masks\", \"*.png\")))\n","\n","    test_size = int(len(images) * split)\n","\n","    train_x, valid_x = train_test_split(images, test_size=test_size, random_state=42)\n","    train_y, valid_y = train_test_split(masks, test_size=test_size, random_state=42)\n","\n","    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n","    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n","\n","    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n","\n","def read_image(path):\n","    path = path.decode()\n","    x = cv2.imread(path, cv2.IMREAD_COLOR)  ## (H, W, 3)\n","    x = cv2.resize(x, (W, H))\n","    x = x/255.0\n","    x = x.astype(np.float32)\n","    return x                                ## (256, 256, 3)\n","\n","def read_mask(path):\n","    path = path.decode()\n","    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (H, W)\n","    x = cv2.resize(x, (W, H))\n","    x = x/255.0\n","    x = x.astype(np.float32)                    ## (256, 256)\n","    x = np.expand_dims(x, axis=-1)              ## (256, 256, 1)\n","    return x\n","\n","def tf_parse(x, y):\n","    def _parse(x, y):\n","        x = read_image(x)\n","        y = read_mask(y)\n","        return x, y\n","\n","    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n","    x.set_shape([H, W, 3])\n","    y.set_shape([H, W, 1])\n","    return x, y\n","\n","def tf_dataset(X, Y, batch):\n","    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n","    dataset = dataset.map(tf_parse)\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.prefetch(10)\n","    return dataset\n","\n","if __name__ == \"__main__\":\n","    \"\"\" Seeding \"\"\"\n","    np.random.seed(42)\n","    tf.random.set_seed(42)\n","\n","    \"\"\" Folder for saving data \"\"\"\n","    create_dir(\"files1\")\n","\n","    \"\"\" Hyperparameters \"\"\"\n","    batch_size = 1\n","    lr = 1e-4 ## (0.0001)\n","    num_epoch = 1\n","    model_path = \"files1/model.h5\"\n","    csv_path = \"files1/data.csv\"\n","\n","    \"\"\" Dataset : 60/20/20 \"\"\"\n","    dataset_path = os.getcwd()\n","    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n","\n","    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n","    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n","    print(f\"Test: {len(test_x)} - {len(test_y)}\")\n","\n","    train_dataset = tf_dataset(train_x, train_y, batch_size)\n","    valid_dataset = tf_dataset(valid_x, valid_y, batch_size)\n","\n","    train_steps = len(train_x)//batch_size\n","    valid_steps = len(valid_x)//batch_size\n","\n","    if len(train_x) % batch_size != 0:\n","        train_steps += 1\n","\n","    if len(valid_x) % batch_size != 0:\n","        valid_steps += 1\n","\n","    \"\"\" Model \"\"\"\n","    model = mnet((H, W, 3))\n","    metrics = [dice_coef, iou, Recall(), Precision()]\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr), metrics=metrics)\n","    model.summary()\n","\n","    callbacks = [\n","        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n","        CSVLogger(csv_path),\n","        TensorBoard(),\n","        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n","    ]\n","\n","    model.fit(\n","        train_dataset,\n","        epochs=num_epoch,\n","        validation_data=valid_dataset,\n","        steps_per_epoch=train_steps,\n","        validation_steps=valid_steps,\n","        callbacks=callbacks\n","    )"]},{"cell_type":"code","source":["#test\n","\n","import os\n","\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n","\n","import numpy as np\n","\n","import cv2\n","\n","import pandas as pd\n","\n","from glob import glob\n","\n","from tqdm import tqdm\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.utils import CustomObjectScope\n","\n","from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n","\n","#from metrics import dice_loss, dice_coef, iou\n","\n","#from train import load_data, create_dir\n","\n"," \n","\n","H = 256\n","\n","W = 256\n","\n"," \n","\n","def read_image(path):\n","\n","    x = cv2.imread(path, cv2.IMREAD_COLOR)  ## (H, W, 3)\n","\n","    x = cv2.resize(x, (W, H))\n","\n","    ori_x = x\n","\n","    x = x/255.0\n","\n","    x = x.astype(np.float32)\n","\n","    x = np.expand_dims(x, axis=0)\n","\n","    return ori_x, x                                ## (1, 256, 256, 3)\n","\n"," \n","\n"," \n","\n","def read_mask(path):\n","\n","    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (H, W)\n","\n","    x = cv2.resize(x, (W, H))\n","\n","    ori_x = x\n","\n","    x = x/255.0\n","\n","    x = x.astype(np.int32)                    ## (256, 256)\n","\n","    return ori_x, x\n","\n"," \n","\n","def save_results(ori_x, ori_y, y_pred, save_image_path):\n","\n","    line = np.ones((H, 10, 3)) * 255\n","\n"," \n","\n","    ori_y = np.expand_dims(ori_y, axis=-1)  ## (256, 256, 1)\n","\n","    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1) ## (256, 256, 3)\n","\n"," \n","\n","    y_pred = np.expand_dims(y_pred, axis=-1)  ## (256, 256, 1)\n","\n","    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) ## (256, 256, 3)\n","\n"," \n","\n","    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred*255], axis=1)\n","\n","    cv2.imwrite(save_image_path, cat_images)\n","\n"," \n","\n","def load_data(dataset_path, split=0.2):\n","\n","    dataset_path=dataset_path+\"/drive/MyDrive/Colab Notebooks/dataset\"\n","\n","    images = sorted(glob(os.path.join(dataset_path, \"images\", \"*.jpg\")))\n","\n","    masks = sorted(glob(os.path.join(dataset_path, \"tooth-semantic-masks\", \"*.png\")))\n","\n"," \n","\n","    test_size = int(len(images) * split)\n","\n"," \n","\n","    train_x, valid_x = train_test_split(images, test_size=test_size, random_state=42)\n","\n","    train_y, valid_y = train_test_split(masks, test_size=test_size, random_state=42)\n","\n"," \n","\n","    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n","\n","    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n","\n"," \n","\n","    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n","\n"," \n","\n"," \n","\n","if __name__ == \"__main__\":\n","\n","    \"\"\" Seeding \"\"\"\n","\n","    np.random.seed(42)\n","\n","    tf.random.set_seed(42)\n","\n"," \n","\n","    \"\"\" Folder for saving results \"\"\"\n","\n","    create_dir(\"results1\")\n","\n"," \n","\n","    \"\"\" Load the model \"\"\"\n","\n","    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n","\n","        model = tf.keras.models.load_model(\"files1/model.h5\")\n","\n"," \n","\n","    \"\"\" Load the test data \"\"\"\n","\n","    dataset_path = os.getcwd()\n","\n","    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(dataset_path)\n","\n"," \n","\n","    SCORE = []\n","\n","    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n","\n","        \"\"\" Exctracting the image name \"\"\"\n","\n","        name = x.split(\"/\")[-1]\n","\n"," \n","\n","        \"\"\" Read the image and mask \"\"\"\n","\n","        ori_x, x = read_image(x)\n","\n","        ori_y, y = read_mask(y)\n","\n"," \n","\n","        \"\"\" Predicting the mask \"\"\"\n","\n","        y_pred = model.predict(x)[0] > 0.5\n","\n","        y_pred = np.squeeze(y_pred, axis=-1)\n","\n","        y_pred = y_pred.astype(np.int32)\n","\n"," \n","\n","        \"\"\" Saving the predicted mask \"\"\"\n","\n","        save_image_path = f\"results1/{name}\"\n","\n","        save_results(ori_x, ori_y, y_pred, save_image_path)\n","\n","        print(save_image_path)\n","\n"," \n","\n","        \"\"\" Flatten the array \"\"\"\n","\n","        y = y.flatten()\n","\n","        y_pred = y_pred.flatten()\n","\n"," \n","\n","        \"\"\" Calculating metrics values \"\"\"\n","\n","        acc_value = accuracy_score(y, y_pred)\n","\n","        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n","\n","        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n","\n","        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n","\n","        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n","\n","        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n","\n"," \n","\n","    \"\"\" mean metrics values \"\"\"\n","\n","    score = [s[1:] for s in SCORE]\n","\n","    score = np.mean(score, axis=0)\n","\n","    print(f\"Accuracy: {score[0]:0.5f}\")\n","\n","    print(f\"F1: {score[1]:0.5f}\")\n","\n","    print(f\"Jaccard: {score[2]:0.5f}\")\n","\n","    print(f\"Recall: {score[3]:0.5f}\")\n","\n","    print(f\"Precision: {score[4]:0.5f}\")\n","\n"," \n","\n","    df = pd.DataFrame(SCORE, columns = [\"Image Name\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n","\n","    df.to_csv(\"files1/score.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVqh_S0UIIMp","executionInfo":{"status":"ok","timestamp":1663852285314,"user_tz":-540,"elapsed":55303,"user":{"displayName":"김화정","userId":"08769136370942470221"}},"outputId":"c519ce52-e143-401e-eadb-de7edd9a8fdf"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 1/300 [00:00<02:44,  1.82it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00093.jpg\n","results1/cate2-00058.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 3/300 [00:00<01:17,  3.85it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate3-00004.jpg\n","results1/cate2-00147.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 5/300 [00:01<01:01,  4.81it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00027.jpg\n","results1/cate2-00014.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 7/300 [00:01<00:55,  5.32it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00040.jpg\n","results1/cate8-00359.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  3%|▎         | 9/300 [00:01<00:52,  5.55it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00055.jpg\n","results1/cate5-00092.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▎         | 11/300 [00:02<00:51,  5.61it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00154.jpg\n","results1/cate8-00109.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▍         | 13/300 [00:02<00:50,  5.65it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00199.jpg\n","results1/cate7-00089.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▌         | 15/300 [00:02<00:49,  5.73it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00421.jpg\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 16/300 [00:03<01:28,  3.21it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00057.jpg\n","results1/cate2-00068.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  6%|▌         | 18/300 [00:03<01:08,  4.14it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00192.jpg\n","results1/cate2-00117.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 20/300 [00:04<00:58,  4.81it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate9-00013.jpg\n","results1/cate6-00157.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 22/300 [00:04<00:53,  5.19it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00333.jpg\n","results1/cate10-00113.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 24/300 [00:05<00:50,  5.51it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00038.jpg\n","results1/cate8-00341.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▊         | 26/300 [00:05<00:48,  5.62it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00138.jpg\n","results1/cate1-00042.jpg\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 28/300 [00:05<00:47,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00426.jpg\n","results1/cate2-00028.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 30/300 [00:06<00:47,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00160.jpg\n","results1/cate8-00277.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█         | 32/300 [00:06<00:47,  5.66it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00065.jpg\n","results1/cate1-00069.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█▏        | 34/300 [00:06<00:46,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00037.jpg\n","results1/cate8-00027.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 12%|█▏        | 36/300 [00:07<00:46,  5.72it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00052.jpg\n","results1/cate8-00152.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 13%|█▎        | 38/300 [00:07<00:45,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00083.jpg\n","results1/cate8-00220.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 13%|█▎        | 40/300 [00:07<00:45,  5.76it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00095.jpg\n","results1/cate8-00379.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 14%|█▍        | 42/300 [00:08<00:45,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00183.jpg\n","results1/cate8-00079.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▍        | 44/300 [00:08<00:44,  5.70it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00170.jpg\n","results1/cate8-00420.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 46/300 [00:08<00:44,  5.75it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00068.jpg\n","results1/cate2-00124.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 16%|█▌        | 48/300 [00:09<00:45,  5.59it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00129.jpg\n","results1/cate8-00179.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 17%|█▋        | 50/300 [00:09<00:44,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00115.jpg\n","results1/cate6-00048.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 17%|█▋        | 52/300 [00:09<00:43,  5.66it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00056.jpg\n","results1/cate5-00032.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 54/300 [00:10<00:42,  5.79it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00021.jpg\n","results1/cate4-00003.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▊        | 56/300 [00:10<00:42,  5.72it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00024.jpg\n","results1/cate7-00099.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 58/300 [00:10<00:42,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00007.jpg\n","results1/cate8-00411.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 60/300 [00:11<00:41,  5.74it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00096.jpg\n","results1/cate2-00189.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 62/300 [00:11<00:41,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00071.jpg\n","results1/cate4-00025.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██▏       | 64/300 [00:12<00:41,  5.74it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00180.jpg\n","results1/cate4-00100.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 66/300 [00:12<00:40,  5.75it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00213.jpg\n","results1/cate4-00099.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 23%|██▎       | 68/300 [00:12<00:40,  5.76it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00034.jpg\n","results1/cate1-00008.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 23%|██▎       | 70/300 [00:13<00:40,  5.75it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00052.jpg\n","results1/cate10-00111.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 24%|██▍       | 72/300 [00:13<00:40,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00015.jpg\n","results1/cate4-00014.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▍       | 74/300 [00:13<00:39,  5.77it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00041.jpg\n","results1/cate8-00439.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 76/300 [00:14<00:38,  5.82it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00033.jpg\n","results1/cate6-00040.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▌       | 78/300 [00:14<00:38,  5.81it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00025.jpg\n","results1/cate4-00134.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 80/300 [00:14<00:38,  5.77it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00061.jpg\n","results1/cate5-00107.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 82/300 [00:15<00:38,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00292.jpg\n","results1/cate8-00417.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 84/300 [00:15<00:37,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00037.jpg\n","results1/cate9-00038.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 29%|██▊       | 86/300 [00:15<00:37,  5.73it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00259.jpg\n","results1/cate5-00091.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 29%|██▉       | 88/300 [00:16<00:36,  5.80it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00088.jpg\n","results1/cate8-00334.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 90/300 [00:16<00:36,  5.77it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00182.jpg\n","results1/cate8-00231.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 31%|███       | 92/300 [00:16<00:36,  5.66it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00214.jpg\n","results1/cate4-00051.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 31%|███▏      | 94/300 [00:17<00:35,  5.72it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00143.jpg\n","results1/cate5-00049.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 32%|███▏      | 96/300 [00:17<00:35,  5.75it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00090.jpg\n","results1/cate10-00072.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 33%|███▎      | 98/300 [00:17<00:35,  5.76it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00038.jpg\n","results1/cate1-00006.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 33%|███▎      | 100/300 [00:18<00:34,  5.75it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00077.jpg\n","results1/cate6-00102.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 34%|███▍      | 102/300 [00:18<00:34,  5.66it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00136.jpg\n","results1/cate4-00004.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▍      | 104/300 [00:18<00:34,  5.64it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00249.jpg\n","results1/cate2-00003.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 106/300 [00:19<00:34,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00016.jpg\n","results1/cate8-00067.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 36%|███▌      | 108/300 [00:19<00:34,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00085.jpg\n","results1/cate4-00022.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 110/300 [00:20<00:33,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00080.jpg\n","results1/cate2-00149.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 112/300 [00:20<00:33,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00044.jpg\n","results1/cate8-00208.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 114/300 [00:20<00:32,  5.70it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00092.jpg\n","results1/cate10-00109.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 39%|███▊      | 116/300 [00:21<00:32,  5.66it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00015.jpg\n","results1/cate8-00415.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 39%|███▉      | 118/300 [00:21<00:31,  5.70it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00011.jpg\n","results1/cate8-00431.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 120/300 [00:21<00:31,  5.74it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00298.jpg\n","results1/cate8-00384.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████      | 122/300 [00:22<00:31,  5.66it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00022.jpg\n","results1/cate2-00197.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████▏     | 124/300 [00:22<00:30,  5.72it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00020.jpg\n","results1/cate9-00032.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 126/300 [00:22<00:30,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00399.jpg\n","results1/cate8-00078.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 43%|████▎     | 128/300 [00:23<00:30,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00099.jpg\n","results1/cate8-00357.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 43%|████▎     | 130/300 [00:23<00:29,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00113.jpg\n","results1/cate2-00037.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 132/300 [00:23<00:29,  5.65it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00008.jpg\n","results1/cate8-00391.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▍     | 134/300 [00:24<00:29,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00382.jpg\n","results1/cate8-00197.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 136/300 [00:24<00:28,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00163.jpg\n","results1/cate10-00092.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▌     | 138/300 [00:24<00:28,  5.64it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00038.jpg\n","results1/cate3-00041.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 47%|████▋     | 140/300 [00:25<00:28,  5.65it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00161.jpg\n","results1/cate4-00068.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 47%|████▋     | 142/300 [00:25<00:28,  5.58it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00064.jpg\n","results1/cate5-00011.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 48%|████▊     | 144/300 [00:26<00:27,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00380.jpg\n","results1/cate2-00148.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▊     | 146/300 [00:26<00:26,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00011.jpg\n","results1/cate6-00167.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 148/300 [00:26<00:27,  5.51it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00130.jpg\n","results1/cate9-00034.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 150/300 [00:27<00:26,  5.56it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00122.jpg\n","results1/cate4-00040.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 152/300 [00:27<00:26,  5.52it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00081.jpg\n","results1/cate5-00070.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████▏    | 154/300 [00:27<00:25,  5.62it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00225.jpg\n","results1/cate8-00273.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 156/300 [00:28<00:25,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00028.jpg\n","results1/cate1-00067.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 158/300 [00:28<00:24,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00099.jpg\n","results1/cate9-00042.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 160/300 [00:28<00:24,  5.65it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate9-00020.jpg\n","results1/cate8-00244.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 54%|█████▍    | 162/300 [00:29<00:24,  5.61it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00442.jpg\n","results1/cate5-00056.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▍    | 164/300 [00:29<00:23,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00106.jpg\n","results1/cate4-00015.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▌    | 166/300 [00:29<00:23,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00047.jpg\n","results1/cate2-00056.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 168/300 [00:30<00:23,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00108.jpg\n","results1/cate7-00053.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 170/300 [00:30<00:22,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00010.jpg\n","results1/cate6-00139.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 172/300 [00:31<00:22,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00017.jpg\n","results1/cate7-00011.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 58%|█████▊    | 174/300 [00:31<00:22,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00055.jpg\n","results1/cate8-00051.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 59%|█████▊    | 176/300 [00:31<00:21,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00071.jpg\n","results1/cate4-00054.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 59%|█████▉    | 178/300 [00:32<00:21,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00107.jpg\n","results1/cate2-00159.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 180/300 [00:32<00:21,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate9-00004.jpg\n","results1/cate8-00123.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 61%|██████    | 182/300 [00:32<00:20,  5.65it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate9-00045.jpg\n","results1/cate3-00003.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 61%|██████▏   | 184/300 [00:33<00:20,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00089.jpg\n","results1/cate1-00040.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 62%|██████▏   | 186/300 [00:33<00:20,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00015.jpg\n","results1/cate9-00031.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 63%|██████▎   | 188/300 [00:33<00:19,  5.61it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00005.jpg\n","results1/cate8-00215.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 63%|██████▎   | 190/300 [00:34<00:19,  5.64it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00066.jpg\n","results1/cate2-00076.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▍   | 192/300 [00:34<00:19,  5.60it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00002.jpg\n","results1/cate3-00022.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▍   | 194/300 [00:34<00:18,  5.70it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00118.jpg\n","results1/cate5-00081.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 196/300 [00:35<00:18,  5.72it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00243.jpg\n","results1/cate2-00001.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 66%|██████▌   | 198/300 [00:35<00:17,  5.76it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00412.jpg\n","results1/cate8-00210.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 67%|██████▋   | 200/300 [00:35<00:17,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00081.jpg\n","results1/cate10-00044.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 67%|██████▋   | 202/300 [00:36<00:17,  5.62it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00096.jpg\n","results1/cate8-00403.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 68%|██████▊   | 204/300 [00:36<00:16,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate3-00045.jpg\n","results1/cate8-00254.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 69%|██████▊   | 206/300 [00:37<00:16,  5.61it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00369.jpg\n","results1/cate10-00021.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 69%|██████▉   | 208/300 [00:37<00:16,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00104.jpg\n","results1/cate8-00313.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 210/300 [00:37<00:15,  5.73it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00108.jpg\n","results1/cate8-00241.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 71%|███████   | 212/300 [00:38<00:15,  5.59it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00011.jpg\n","results1/cate1-00043.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 71%|███████▏  | 214/300 [00:38<00:15,  5.62it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00017.jpg\n","results1/cate6-00165.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 72%|███████▏  | 216/300 [00:38<00:14,  5.70it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00066.jpg\n","results1/cate8-00432.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 218/300 [00:39<00:14,  5.70it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00006.jpg\n","results1/cate7-00112.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 220/300 [00:39<00:14,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00151.jpg\n","results1/cate9-00021.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 222/300 [00:39<00:13,  5.62it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00020.jpg\n","results1/cate8-00325.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▍  | 224/300 [00:40<00:13,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00227.jpg\n","results1/cate4-00095.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 226/300 [00:40<00:13,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00010.jpg\n","results1/cate4-00063.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 76%|███████▌  | 228/300 [00:40<00:12,  5.65it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00067.jpg\n","results1/cate10-00016.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 230/300 [00:41<00:12,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00453.jpg\n","results1/cate8-00162.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 77%|███████▋  | 232/300 [00:41<00:12,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00441.jpg\n","results1/cate8-00434.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 78%|███████▊  | 234/300 [00:41<00:11,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00029.jpg\n","results1/cate4-00036.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▊  | 236/300 [00:42<00:11,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00073.jpg\n","results1/cate6-00072.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▉  | 238/300 [00:42<00:10,  5.73it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00449.jpg\n","results1/cate8-00047.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 240/300 [00:43<00:10,  5.74it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00117.jpg\n","results1/cate7-00107.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 81%|████████  | 242/300 [00:43<00:10,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00067.jpg\n","results1/cate8-00232.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 81%|████████▏ | 244/300 [00:43<00:09,  5.70it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00037.jpg\n","results1/cate10-00098.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 82%|████████▏ | 246/300 [00:44<00:09,  5.52it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00105.jpg\n","results1/cate2-00035.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 248/300 [00:44<00:09,  5.60it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00095.jpg\n","results1/cate8-00222.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 250/300 [00:44<00:08,  5.64it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate5-00059.jpg\n","results1/cate8-00350.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 84%|████████▍ | 252/300 [00:45<00:08,  5.53it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00056.jpg\n","results1/cate6-00073.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 85%|████████▍ | 254/300 [00:45<00:08,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00084.jpg\n","results1/cate9-00009.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 85%|████████▌ | 256/300 [00:45<00:07,  5.69it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00112.jpg\n","results1/cate6-00153.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 86%|████████▌ | 258/300 [00:46<00:07,  5.71it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00046.jpg\n","results1/cate4-00097.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 87%|████████▋ | 260/300 [00:46<00:07,  5.68it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00065.jpg\n","results1/cate7-00102.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 87%|████████▋ | 262/300 [00:46<00:06,  5.57it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00003.jpg\n","results1/cate6-00142.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 88%|████████▊ | 264/300 [00:47<00:06,  5.64it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00145.jpg\n","results1/cate2-00047.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 89%|████████▊ | 266/300 [00:47<00:06,  5.62it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00049.jpg\n","results1/cate2-00170.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 89%|████████▉ | 268/300 [00:47<00:05,  5.61it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00039.jpg\n","results1/cate1-00038.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 270/300 [00:48<00:05,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00082.jpg\n","results1/cate8-00111.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 91%|█████████ | 272/300 [00:48<00:05,  5.56it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00013.jpg\n","results1/cate8-00116.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 91%|█████████▏| 274/300 [00:49<00:04,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00342.jpg\n","results1/cate9-00014.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 92%|█████████▏| 276/300 [00:49<00:04,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00131.jpg\n","results1/cate9-00029.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 93%|█████████▎| 278/300 [00:49<00:03,  5.65it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00161.jpg\n","results1/cate10-00008.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 93%|█████████▎| 280/300 [00:50<00:03,  5.60it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00026.jpg\n","results1/cate8-00183.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 94%|█████████▍| 282/300 [00:50<00:03,  5.61it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00065.jpg\n","results1/cate8-00115.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▍| 284/300 [00:50<00:02,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00445.jpg\n","results1/cate7-00012.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 286/300 [00:51<00:02,  5.60it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate8-00257.jpg\n","results1/cate10-00101.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 96%|█████████▌| 288/300 [00:51<00:02,  5.64it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate1-00051.jpg\n","results1/cate2-00030.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 290/300 [00:51<00:01,  5.67it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate10-00026.jpg\n","results1/cate6-00025.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 292/300 [00:52<00:01,  5.59it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate2-00198.jpg\n","results1/cate2-00061.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 98%|█████████▊| 294/300 [00:52<00:01,  5.64it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00035.jpg\n","results1/cate7-00105.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▊| 296/300 [00:52<00:00,  5.66it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate6-00056.jpg\n","results1/cate2-00217.jpg\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▉| 298/300 [00:53<00:00,  5.60it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate7-00090.jpg\n","results1/cate9-00017.jpg\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 300/300 [00:53<00:00,  5.59it/s]"]},{"output_type":"stream","name":"stdout","text":["results1/cate4-00112.jpg\n","Accuracy: 0.90548\n","F1: 0.68880\n","Jaccard: 0.53422\n","Recall: 0.57611\n","Precision: 0.89486\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["dataset_path=os.getcwd()\n","dataset_path=dataset_path+ \"/content/drive/MyDrive/Colab Notebooks/dataset\""],"metadata":{"id":"tK1TcuhbuA0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1663043691890,"user":{"displayName":"김화정","userId":"08769136370942470221"},"user_tz":-540},"id":"DTYC6uTvCiz9","outputId":"cc7cb028-8f95-48ab-805f-f48ef84be28f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["import os\n","print(os.getcwd())"]}],"metadata":{"colab":{"provenance":[{"file_id":"1k7TWUehwSNPmO_A8-Yq5vfgZaoEopAav","timestamp":1663213521796}],"collapsed_sections":[],"mount_file_id":"1k7TWUehwSNPmO_A8-Yq5vfgZaoEopAav","authorship_tag":"ABX9TyM7lgRSTU2KmjUi5U5kKo0Y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}